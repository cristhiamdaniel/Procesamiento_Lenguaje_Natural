{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jugando con la gramática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temas a tratar:\n",
    "\n",
    "* Contando sustantivos (plurales y singulares).\n",
    "* Obtener el análisis de dependencia.\n",
    "* División de frases en cláusulas.\n",
    "* Extracción de trozos sustantivos.\n",
    "* Entidades extractoras y relaciones.\n",
    "* Extraer sujetos y objetos de la oración.\n",
    "* Encontrar referencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Contar sustantivos - sustantivos plurales y singulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando los módulos necesarios\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_nltk(text):\n",
    "    return nltk.tokenize.word_tokenize(text)\n",
    "\n",
    "def pos_tag_nltk(text):\n",
    "    words = tokenize_nltk(text)\n",
    "    words_with_pos = nltk.pos_tag(words)\n",
    "    return words_with_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del texto en inglés\n",
    "filename = \"pv.txt\"\n",
    "file = open(filename, \"r\", encoding=\"utf-8\")\n",
    "text = file.read()\n",
    "text = text.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'DT'), ('photovoltaic', 'JJ'), ('array', 'NN'), ('(', '('), ('PVA', 'NNP'), (')', ')'), ('simulation', 'NN'), ('model', 'NN'), ('to', 'TO'), ('be', 'VB'), ('used', 'VBN'), ('in', 'IN'), ('Matlab-Simulink', 'NNP'), ('GUI', 'NNP'), ('environment', 'NN'), ('is', 'VBZ'), ('developed', 'VBN'), ('and', 'CC'), ('presented', 'VBN'), ('in', 'IN'), ('this', 'DT'), ('paper', 'NN'), ('.', '.'), ('The', 'DT'), ('model', 'NN'), ('is', 'VBZ'), ('developed', 'VBN'), ('using', 'VBG'), ('basic', 'JJ'), ('circuit', 'NN'), ('equations', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('photovoltaic', 'NN'), ('(', '('), ('PV', 'NNP'), (')', ')'), ('solar', 'VBP'), ('cells', 'NNS'), ('including', 'VBG'), ('the', 'DT'), ('effects', 'NNS'), ('of', 'IN'), ('solar', 'JJ'), ('irradiation', 'NN'), ('and', 'CC'), ('temperature', 'NN'), ('changes', 'NNS'), ('.', '.'), ('The', 'DT'), ('new', 'JJ'), ('model', 'NN'), ('was', 'VBD'), ('tested', 'VBN'), ('using', 'VBG'), ('a', 'DT'), ('directly', 'RB'), ('coupled', 'VBN'), ('dc', 'NN'), ('load', 'NN'), ('as', 'RB'), ('well', 'RB'), ('as', 'IN'), ('ac', 'JJ'), ('load', 'NN'), ('via', 'IN'), ('an', 'DT'), ('inverter', 'NN'), ('.', '.'), ('Test', 'NNP'), ('and', 'CC'), ('validation', 'NN'), ('studies', 'NNS'), ('with', 'IN'), ('proper', 'JJ'), ('load', 'NN'), ('matching', 'VBG'), ('circuits', 'NNS'), ('are', 'VBP'), ('simulated', 'VBN'), ('and', 'CC'), ('results', 'NNS'), ('are', 'VBP'), ('presented', 'VBN'), ('here', 'RB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Hacer parte del etiquetado del habla\n",
    "words_with_pos = pos_tag_nltk(text)\n",
    "print(words_with_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la función get_nouns, para filtrar los sustantivos:\n",
    "def get_nouns(words_with_pos):\n",
    "    noun_set = [\"NN\", \"NNS\"]\n",
    "    nouns = [word for word in words_with_pos if  word[1] in noun_set]\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('array', 'NN'), ('simulation', 'NN'), ('model', 'NN'), ('environment', 'NN'), ('paper', 'NN'), ('model', 'NN'), ('circuit', 'NN'), ('equations', 'NNS'), ('photovoltaic', 'NN'), ('cells', 'NNS'), ('effects', 'NNS'), ('irradiation', 'NN'), ('temperature', 'NN'), ('changes', 'NNS'), ('model', 'NN'), ('dc', 'NN'), ('load', 'NN'), ('load', 'NN'), ('inverter', 'NN'), ('validation', 'NN'), ('studies', 'NNS'), ('load', 'NN'), ('circuits', 'NNS'), ('results', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "# Ejecutamos la función anterior en la lista de palabras etiquetadas con POS:\n",
    "nouns = get_nouns(words_with_pos)\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para determinar si un sustantivo es singular o plural, tenemos dos opciones. La primera opción es usar las etiquetas NLTK, donde NN indica un sustantivo singular y NNS indica un sustantivo plural. <br>\n",
    "\n",
    "La siguiente función utiliza las etiquetas NLTK y devuelve True si el sustantivo de entrada es plural:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_plural_nltk(noun_info):\n",
    "    pos = noun_info[1]\n",
    "    if (pos == \"NNS\"):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_plural_nltk(('equations', 'NNS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_plural_nltk(('photovoltaic', 'NN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La otra opción es usar la clase WordNetLemmatizer en el paquete nltk.stem. La siguiente función devuelve True si el sustantivo es plural:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_plural_wn(noun):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemma = wnl.lemmatize(noun, 'n')\n",
    "    plural = True if noun is not lemma else False\n",
    "    return plural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_plural_wn('equations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_plural_wn('photovoltaic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La siguiente función cambiará un sustantivo singular en plural:\n",
    "def get_plural(singular_noun):\n",
    "    p = inflect.engine()\n",
    "    return p.plural(singular_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'photovoltaics'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_plural('photovoltaic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La siguiente función cambiará un sustantivo singular en plural:\n",
    "def get_singular(plural_noun):\n",
    "    p = inflect.engine()\n",
    "    plural = p.singular_noun(plural_noun)\n",
    "    if (plural):\n",
    "        return plural\n",
    "    else:\n",
    "        return plural_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'equation'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_singular('equations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos usar las dos funciones anteriores para devolver una lista de sustantivos cambiados en plural o singular, dependiendo del sustantivo original. El siguiente código usa la función is_plural_wn para determinar si el sustantivo es plural. También puede usar la función is_plural_nltk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plurals_wn(words_with_pos):\n",
    "    other_nouns = []\n",
    "    for noun_info in words_with_pos:\n",
    "        word = noun_info[0]\n",
    "        plural = is_plural_wn(word)\n",
    "        if (plural):\n",
    "            singular = get_singular(word)\n",
    "            other_nouns.append(singular)\n",
    "        else:\n",
    "            plural = get_plural(word)\n",
    "            other_nouns.append(plural)\n",
    "    \n",
    "    return other_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arrays', 'simulations', 'models', 'environments', 'papers', 'models', 'circuits', 'equation', 'photovoltaics', 'cell', 'effect', 'irradiations', 'temperatures', 'change', 'models', 'dcs', 'loads', 'loads', 'inverters', 'validations', 'study', 'loads', 'circuit', 'result']\n"
     ]
    }
   ],
   "source": [
    "# Utilice la función anterior para devolver una lista de sustantivos modificados:\n",
    "other_nouns_wn = plurals_wn(nouns)\n",
    "print(other_nouns_wn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obteniendo análisis de dependencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librería\n",
    "import spacy\n",
    "\n",
    "\n",
    "'''\n",
    "Recurrir al reporte de errores\n",
    "'''\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando la frase que se va a analizar\n",
    "sentence = 'I have seldom heard him mention her under any other name.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando el motor spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesesando la oración con el motor spacy\n",
    "doc = nlp(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La información de dependencias estará contenida en el objeto doc. Podemos ver las etiquetas de dependencias haciendo un bucle a través de los tokens en doc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t nsubj \t nominal subject\n",
      "have \t aux \t auxiliary\n",
      "seldom \t advmod \t adverbial modifier\n",
      "heard \t ROOT \t None\n",
      "him \t nsubj \t nominal subject\n",
      "mention \t ccomp \t clausal complement\n",
      "her \t dobj \t direct object\n",
      "under \t prep \t prepositional modifier\n",
      "any \t det \t determiner\n",
      "other \t amod \t adjectival modifier\n",
      "name \t pobj \t object of preposition\n",
      ". \t punct \t punctuation\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, \"\\t\", token.dep_, \"\\t\", spacy.explain(token.dep_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para explorar la estructura de análisis de dependencias, podemos usar los atributos de la clase Token. Usando sus atributos **ancestors** e **children**, podemos obtener los tokens de los que depende este token y los tokens que dependen de él, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "['heard']\n",
      "have\n",
      "['heard']\n",
      "seldom\n",
      "['heard']\n",
      "heard\n",
      "[]\n",
      "him\n",
      "['mention', 'heard']\n",
      "mention\n",
      "['heard']\n",
      "her\n",
      "['mention', 'heard']\n",
      "under\n",
      "['mention', 'heard']\n",
      "any\n",
      "['name', 'under', 'mention', 'heard']\n",
      "other\n",
      "['name', 'under', 'mention', 'heard']\n",
      "name\n",
      "['under', 'mention', 'heard']\n",
      ".\n",
      "['heard']\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)\n",
    "    ancestors = [t.text for t in token.ancestors]\n",
    "    print(ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "[]\n",
      "have\n",
      "[]\n",
      "seldom\n",
      "[]\n",
      "heard\n",
      "['I', 'have', 'seldom', 'mention', '.']\n",
      "him\n",
      "[]\n",
      "mention\n",
      "['him', 'her', 'under']\n",
      "her\n",
      "[]\n",
      "under\n",
      "['name']\n",
      "any\n",
      "[]\n",
      "other\n",
      "[]\n",
      "name\n",
      "['any', 'other']\n",
      ".\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# tokens secundarios\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "    children = [t.text for t in token.children]\n",
    "    print(children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "['I']\n",
      "have\n",
      "['have']\n",
      "seldom\n",
      "['seldom']\n",
      "heard\n",
      "['I', 'have', 'seldom', 'heard', 'him', 'mention', 'her', 'under', 'any', 'other', 'name', '.']\n",
      "him\n",
      "['him']\n",
      "mention\n",
      "['him', 'mention', 'her', 'under', 'any', 'other', 'name']\n",
      "her\n",
      "['her']\n",
      "under\n",
      "['under', 'any', 'other', 'name']\n",
      "any\n",
      "['any']\n",
      "other\n",
      "['other']\n",
      "name\n",
      "['any', 'other', 'name']\n",
      ".\n",
      "['.']\n"
     ]
    }
   ],
   "source": [
    "# También podemos ver el subárbol en el que está el token:\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "    subtree = [t.text for t in token.subtree]\n",
    "    print(subtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probemos con español**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "python -m spacy download es_core_news_sm\n",
    "'''\n",
    "nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Me gusta la programación y el mundo maker.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Me gusta la programación y el mundo maker."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(sentence)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me \t obj \t object\n",
      "gusta \t ROOT \t None\n",
      "la \t det \t determiner\n",
      "programación \t nsubj \t nominal subject\n",
      "y \t cc \t coordinating conjunction\n",
      "el \t det \t determiner\n",
      "mundo \t conj \t conjunct\n",
      "maker \t flat \t flat multiword expression\n",
      ". \t punct \t punctuation\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, \"\\t\", token.dep_, \"\\t\", spacy.explain(token.dep_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me\n",
      "['gusta']\n",
      "gusta\n",
      "[]\n",
      "la\n",
      "['programación', 'gusta']\n",
      "programación\n",
      "['gusta']\n",
      "y\n",
      "['mundo', 'programación', 'gusta']\n",
      "el\n",
      "['mundo', 'programación', 'gusta']\n",
      "mundo\n",
      "['programación', 'gusta']\n",
      "maker\n",
      "['mundo', 'programación', 'gusta']\n",
      ".\n",
      "['gusta']\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)\n",
    "    ancestors = [t.text for t in token.ancestors]\n",
    "    print(ancestors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir la frase en cláusulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
